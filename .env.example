# LGTM Configuration Example
# Copy this file to .env and customize for your needs

# Required: AI API Configuration
LGTM_API_URL="https://api.openai.com/v1/chat/completions"
LGTM_API_KEY="your-openai-api-key-here"

# Optional: Model Configuration
LGTM_MODEL="gpt-4"
LGTM_TEMPERATURE="0.3"

# Optional: Git Diff Processing
LGTM_MAX_CHUNK_SIZE=4000
LGTM_MAX_TOKENS=100
LGTM_AUTO_PUSH=false
LGTM_IGNORE_PATTERNS="*.log,*.tmp,node_modules/*,*.min.js,*.map,*.lock,*.md,*.txt,*.json,*.yaml,*.yml,*.xml,*.csv"
LGTM_INCLUDE_EXTENSIONS=".js,.ts,.py,.go,.rs,.java,.cpp,.c,.h,.php,.rb,.sh,.bash,.zsh"

# Alternative API Examples:

# Anthropic Claude
# LGTM_API_URL="https://api.anthropic.com/v1/messages"
# LGTM_MODEL="claude-3-sonnet-20240229"

# Local/Self-hosted API (Ollama, etc.)
# LGTM_API_URL="http://localhost:11434/v1/chat/completions"
# LGTM_MODEL="llama2"

# Usage Examples:
# Load this file: source .env
# Then run: ./lgtm.sh --dry-run
# Silent mode: ./lgtm.sh --silent
# Auto-commit: ./lgtm.sh --auto-commit
# Auto-commit and push: ./lgtm.sh --auto-commit --push
# Custom tokens: ./lgtm.sh --max-tokens 200
